{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeepPurpose import utils, dataset\n",
    "from DeepPurpose import DTI as models\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KIBA dataset loading\n",
    "\n",
    "path = 'C:\\\\Users\\\\user\\\\Desktop\\\\DTI\\\\Database'\n",
    "\n",
    "affinity = pd.read_csv(path + '/KIBA/affinity.txt', header=None, sep = '\\t')\n",
    "affinity = affinity.fillna(-1)\n",
    "\n",
    "with open(path + '/KIBA/target_seq.txt') as f:\n",
    "    target = json.load(f)\n",
    "\n",
    "with open(path + '/KIBA/SMILES.txt') as f:\n",
    "    drug = json.load(f)\n",
    "\n",
    "target = list(target.values())\n",
    "drug = list(drug.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KIBA dataset loading : target sequence edited version\n",
    "\n",
    "target_edit = pd.read_csv(path + '/KIBA/KIBA_target_seq_edit.tsv', sep = '\\t')\n",
    "target_edit = target_edit['new_sequence'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = False\n",
    "convert_to_log = False\n",
    "threshold = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target / target_edit\n",
    "\n",
    "SMILES = []\n",
    "Target_seq = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(drug)):\n",
    "    for j in range(len(target_edit)): # target / target_edit 수정\n",
    "        if affinity.values[i, j] != -1:\n",
    "            SMILES.append(drug[i])\n",
    "            Target_seq.append(target_edit[j]) # target / target_edit 수정\n",
    "            y.append(affinity.values[i, j])\n",
    "            \n",
    "if binary:\n",
    "\t\tprint('Default binary threshold for the binding affinity scores are 30, you can adjust it by using the \"threshold\" parameter')\n",
    "\t\ty = [1 if i else 0 for i in np.array(y) < threshold]\n",
    "else:\n",
    "\tif convert_to_log:\n",
    "\t\tprint('Default set to logspace (nM -> p) for easier regression')\n",
    "\t\ty = dataset.convert_y_unit(np.array(y), 'nM', 'p')\n",
    "\telse:\n",
    "\t\ty = y\n",
    "   \n",
    "X_drugs, X_targets, y = np.array(SMILES), np.array(Target_seq), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoding, target_encoding = 'CNN', 'CNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug Target Interaction Prediction Mode...\n",
      "in total: 118254 drug-target pairs\n",
      "encoding drug...\n",
      "unique drugs: 2068\n",
      "encoding protein...\n",
      "unique target sequence: 229\n",
      "splitting dataset...\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Target Sequence</th>\n",
       "      <th>Label</th>\n",
       "      <th>drug_encoding</th>\n",
       "      <th>target_encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl</td>\n",
       "      <td>MTVKTEAAKGTLTYSRMRGMVAILIAFMKQRRMGLNDFIQKIANNS...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>[C, O, C, 1, =, C, (, C, =, C, 2, C, (, =, C, ...</td>\n",
       "      <td>[M, T, V, K, T, E, A, A, K, G, T, L, T, Y, S, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          SMILES  \\\n",
       "0  COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
       "\n",
       "                                     Target Sequence  Label  \\\n",
       "0  MTVKTEAAKGTLTYSRMRGMVAILIAFMKQRRMGLNDFIQKIANNS...   11.1   \n",
       "\n",
       "                                       drug_encoding  \\\n",
       "0  [C, O, C, 1, =, C, (, C, =, C, 2, C, (, =, C, ...   \n",
       "\n",
       "                                     target_encoding  \n",
       "0  [M, T, V, K, T, E, A, A, K, G, T, L, T, Y, S, ...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, val, test = utils.data_process(X_drugs, X_targets, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2],\n",
    "                                random_seed = 1)\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_process : parameter\n",
    "\n",
    "X_drug = X_drugs\n",
    "X_target = X_targets\n",
    "y=y\n",
    "drug_encoding='CNN'\n",
    "target_encoding='CNN'\n",
    "split_method = 'random'\n",
    "frac = [0.7, 0.1, 0.2]\n",
    "random_seed = 1\n",
    "sample_frac = 1\n",
    "mode = 'DTI'\n",
    "X_drug_ = None\n",
    "X_target_ = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug Target Interaction Prediction Mode...\n",
      "in total: 118254 drug-target pairs\n"
     ]
    }
   ],
   "source": [
    "# data_process : dataframe\n",
    "\n",
    "if random_seed == 'TDC':\n",
    "\trandom_seed = 1234\n",
    "#property_prediction_flag = X_target is None\n",
    "property_prediction_flag, function_prediction_flag, DDI_flag, PPI_flag, DTI_flag = False, False, False, False, False\n",
    "\n",
    "if (X_drug is not None) and (X_target is not None):\n",
    "\tDTI_flag = True\n",
    "\tif (X_drug is None) or (X_target is None):\n",
    "\t\traise AttributeError(\"Target pair sequence should be in X_target, X_drug\")\n",
    "else:\n",
    "\traise AttributeError(\"Please use the correct mode. Currently, we support DTI, DDI, PPI, Drug Property Prediction and Protein Function Prediction...\")\n",
    "\n",
    "if split_method == 'repurposing_VS':\n",
    "\ty = [-1]*len(X_drug) # create temp y for compatitibility\n",
    "\n",
    "if DTI_flag:\n",
    "\tprint('Drug Target Interaction Prediction Mode...')\n",
    "\tif isinstance(X_target, str):\n",
    "\t\tX_target = [X_target]\n",
    "\tif len(X_target) == 1:\n",
    "\t\t# one target high throughput screening setting\n",
    "\t\tX_target = np.tile(X_target, (length_func(X_drug), ))\n",
    "\n",
    "\tdf_data = pd.DataFrame(zip(X_drug, X_target, y))\n",
    "\tdf_data.rename(columns={0:'SMILES',\n",
    "\t\t\t\t\t\t\t1: 'Target Sequence',\n",
    "\t\t\t\t\t\t\t2: 'Label'}, \n",
    "\t\t\t\t\t\t\tinplace=True)\n",
    "\tprint('in total: ' + str(len(df_data)) + ' drug-target pairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding drug...\n",
      "unique drugs: 2068\n",
      "encoding protein...\n",
      "unique target sequence: 229\n",
      "splitting dataset...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# data_process : endcoding & splitting\n",
    "\n",
    "if sample_frac != 1:\n",
    "\tdf_data = df_data.sample(frac = sample_frac) #.reset_index(drop = True)\n",
    "\tprint('after subsample: ' + str(len(df_data)) + ' data points...') \n",
    "\n",
    "if DTI_flag:\n",
    "\tdf_data = utils.encode_drug(df_data, drug_encoding)\n",
    "\tdf_data = utils.encode_protein(df_data, target_encoding)\n",
    "\n",
    "# dti split\n",
    "if DTI_flag:\n",
    "\tif split_method == 'repurposing_VS':\n",
    "\t\tpass\n",
    "\telse:\n",
    "\t\tprint('splitting dataset...')\n",
    "\n",
    "\tif split_method == 'random': \n",
    "\t\ttrain, val, test = utils.create_fold(df_data, random_seed, frac)\n",
    "\telif split_method == 'cold_drug':\n",
    "\t\ttrain, val, test = utils.create_fold_setting_cold_drug(df_data, random_seed, frac)\n",
    "\telif split_method == 'HTS':\n",
    "\t\ttrain, val, test = utils.create_fold_setting_cold_drug(df_data, random_seed, frac)\n",
    "\t\tval = pd.concat([val[val.Label == 1].drop_duplicates(subset = 'SMILES'), val[val.Label == 0]])\n",
    "\t\ttest = pd.concat([test[test.Label == 1].drop_duplicates(subset = 'SMILES'), test[test.Label == 0]])        \n",
    "\telif split_method == 'cold_protein':\n",
    "\t\ttrain, val, test = utils.create_fold_setting_cold_protein(df_data, random_seed, frac)\n",
    "\telif split_method == 'repurposing_VS':\n",
    "\t\ttrain = df_data\n",
    "\t\tval = df_data\n",
    "\t\ttest = df_data\n",
    "\telif split_method == 'no_split':\n",
    "\t\tprint('do not do train/test split on the data for already splitted data')\n",
    "\t\tresults = df_data.reset_index(drop=True)\n",
    "\telse:\n",
    "\t\traise AttributeError(\"Please select one of the three split method: random, cold_drug, cold_target!\")\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save & reset index\n",
    "train.to_csv('C:\\\\Users\\\\user\\\\Desktop\\\\DTI\\\\Database\\\\KIBA\\\\KIBA_edit_train.tsv', sep='\\t', index=True)\n",
    "val.to_csv('C:\\\\Users\\\\user\\\\Desktop\\\\DTI\\\\Database\\\\KIBA\\\\KIBA_edit_val.tsv', sep='\\t', index=True)\n",
    "test.to_csv('C:\\\\Users\\\\user\\\\Desktop\\\\DTI\\\\Database\\\\KIBA\\\\KIBA_edit_test.tsv', sep='\\t', index=True)\n",
    "train, val, test = train.reset_index(drop=True), val.reset_index(drop=True), test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration genreration\n",
    "config = utils.generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         test_every_X_epoch = 10, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 128,\n",
    "                         hidden_dim_drug = 128,\n",
    "                         cnn_drug_filters = [32,64,96],\n",
    "                         cnn_drug_kernels = [4,6,8],\n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_target_kernels = [4,8,12]\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DeepPurpose.DTI.DBTA at 0x1db9d065ad0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model initialization\n",
    "model = models.model_initialize(**config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 1 GPU!\n",
      "--- Data Preparation ---\n",
      "--- Go for Training ---\n",
      "Training at Epoch 1 iteration 0 with loss 136.072. Total time 0.00083 hours\n",
      "Training at Epoch 1 iteration 100 with loss 0.73228. Total time 0.01111 hours\n",
      "Training at Epoch 1 iteration 200 with loss 1.01411. Total time 0.02138 hours\n",
      "Training at Epoch 1 iteration 300 with loss 0.77544. Total time 0.03138 hours\n",
      "Training at Epoch 1 iteration 400 with loss 0.77637. Total time 0.04166 hours\n",
      "Training at Epoch 1 iteration 500 with loss 1.08254. Total time 0.05166 hours\n",
      "Training at Epoch 1 iteration 600 with loss 0.63626. Total time 0.06194 hours\n",
      "Validation at Epoch 1 with loss:0.50306, MSE: 0.63806 , Pearson Correlation: 0.50964 with p-value: 0.00E+00 , Concordance Index: 0.70868\n",
      "Training at Epoch 2 iteration 0 with loss 0.79376. Total time 0.07472 hours\n",
      "Training at Epoch 2 iteration 100 with loss 0.69896. Total time 0.085 hours\n",
      "Training at Epoch 2 iteration 200 with loss 0.92241. Total time 0.09555 hours\n",
      "Training at Epoch 2 iteration 300 with loss 0.84748. Total time 0.10583 hours\n",
      "Training at Epoch 2 iteration 400 with loss 0.64541. Total time 0.11555 hours\n",
      "Training at Epoch 2 iteration 500 with loss 0.91568. Total time 0.12583 hours\n",
      "Training at Epoch 2 iteration 600 with loss 0.56116. Total time 0.13611 hours\n",
      "Validation at Epoch 2 with loss:0.75062, MSE: 0.74502 , Pearson Correlation: 0.58300 with p-value: 0.00E+00 , Concordance Index: 0.73477\n",
      "Training at Epoch 3 iteration 0 with loss 0.81674. Total time 0.14916 hours\n",
      "Training at Epoch 3 iteration 100 with loss 0.52259. Total time 0.15944 hours\n",
      "Training at Epoch 3 iteration 200 with loss 0.42009. Total time 0.16972 hours\n",
      "Training at Epoch 3 iteration 300 with loss 0.48617. Total time 0.18027 hours\n",
      "Training at Epoch 3 iteration 400 with loss 0.55970. Total time 0.19055 hours\n",
      "Training at Epoch 3 iteration 500 with loss 0.61251. Total time 0.20083 hours\n",
      "Training at Epoch 3 iteration 600 with loss 0.69620. Total time 0.21138 hours\n",
      "Validation at Epoch 3 with loss:0.51604, MSE: 0.49578 , Pearson Correlation: 0.61996 with p-value: 0.00E+00 , Concordance Index: 0.74501\n",
      "Training at Epoch 4 iteration 0 with loss 0.45671. Total time 0.22444 hours\n",
      "Training at Epoch 4 iteration 100 with loss 0.64952. Total time 0.23472 hours\n",
      "Training at Epoch 4 iteration 200 with loss 0.88716. Total time 0.24527 hours\n",
      "Training at Epoch 4 iteration 300 with loss 0.61610. Total time 0.25555 hours\n",
      "Training at Epoch 4 iteration 400 with loss 0.54110. Total time 0.26583 hours\n",
      "Training at Epoch 4 iteration 500 with loss 0.67551. Total time 0.27638 hours\n",
      "Training at Epoch 4 iteration 600 with loss 0.62594. Total time 0.28666 hours\n",
      "Validation at Epoch 4 with loss:0.69536, MSE: 0.61575 , Pearson Correlation: 0.63785 with p-value: 0.00E+00 , Concordance Index: 0.75156\n",
      "Training at Epoch 5 iteration 0 with loss 0.85470. Total time 0.29944 hours\n",
      "Training at Epoch 5 iteration 100 with loss 0.57014. Total time 0.30916 hours\n",
      "Training at Epoch 5 iteration 200 with loss 0.51790. Total time 0.31888 hours\n",
      "Training at Epoch 5 iteration 300 with loss 0.40283. Total time 0.32861 hours\n",
      "Training at Epoch 5 iteration 400 with loss 0.66553. Total time 0.33833 hours\n",
      "Training at Epoch 5 iteration 500 with loss 0.57669. Total time 0.34805 hours\n",
      "Training at Epoch 5 iteration 600 with loss 0.52019. Total time 0.35777 hours\n",
      "Validation at Epoch 5 with loss:0.34849, MSE: 0.41186 , Pearson Correlation: 0.64616 with p-value: 0.00E+00 , Concordance Index: 0.75547\n",
      "Training at Epoch 6 iteration 0 with loss 0.50189. Total time 0.37027 hours\n",
      "Training at Epoch 6 iteration 100 with loss 0.69593. Total time 0.38 hours\n",
      "Training at Epoch 6 iteration 200 with loss 0.44108. Total time 0.39 hours\n",
      "Training at Epoch 6 iteration 300 with loss 0.53049. Total time 0.39972 hours\n",
      "Training at Epoch 6 iteration 400 with loss 0.54193. Total time 0.40944 hours\n",
      "Training at Epoch 6 iteration 500 with loss 0.57334. Total time 0.41916 hours\n",
      "Training at Epoch 6 iteration 600 with loss 0.47983. Total time 0.42888 hours\n",
      "Validation at Epoch 6 with loss:0.55809, MSE: 0.42088 , Pearson Correlation: 0.65018 with p-value: 0.00E+00 , Concordance Index: 0.75533\n",
      "Training at Epoch 7 iteration 0 with loss 0.44322. Total time 0.44138 hours\n",
      "Training at Epoch 7 iteration 100 with loss 0.43133. Total time 0.45111 hours\n",
      "Training at Epoch 7 iteration 200 with loss 0.56936. Total time 0.46083 hours\n",
      "Training at Epoch 7 iteration 300 with loss 0.61086. Total time 0.47055 hours\n",
      "Training at Epoch 7 iteration 400 with loss 0.65743. Total time 0.48027 hours\n",
      "Training at Epoch 7 iteration 500 with loss 0.51381. Total time 0.49027 hours\n",
      "Training at Epoch 7 iteration 600 with loss 0.66890. Total time 0.5 hours\n",
      "Validation at Epoch 7 with loss:0.65685, MSE: 0.49272 , Pearson Correlation: 0.67754 with p-value: 0.00E+00 , Concordance Index: 0.76483\n",
      "Training at Epoch 8 iteration 0 with loss 0.45400. Total time 0.51277 hours\n",
      "Training at Epoch 8 iteration 100 with loss 0.55604. Total time 0.5225 hours\n",
      "Training at Epoch 8 iteration 200 with loss 0.76829. Total time 0.53222 hours\n",
      "Training at Epoch 8 iteration 300 with loss 0.79988. Total time 0.54194 hours\n",
      "Training at Epoch 8 iteration 400 with loss 0.49153. Total time 0.55166 hours\n",
      "Training at Epoch 8 iteration 500 with loss 0.82485. Total time 0.56111 hours\n",
      "Training at Epoch 8 iteration 600 with loss 0.46128. Total time 0.57083 hours\n",
      "Validation at Epoch 8 with loss:0.27056, MSE: 0.35542 , Pearson Correlation: 0.70390 with p-value: 0.00E+00 , Concordance Index: 0.77537\n",
      "Training at Epoch 9 iteration 0 with loss 0.47769. Total time 0.58333 hours\n",
      "Training at Epoch 9 iteration 100 with loss 0.38155. Total time 0.59305 hours\n",
      "Training at Epoch 9 iteration 200 with loss 0.52052. Total time 0.60277 hours\n",
      "Training at Epoch 9 iteration 300 with loss 0.49425. Total time 0.6125 hours\n",
      "Training at Epoch 9 iteration 400 with loss 0.56591. Total time 0.62222 hours\n",
      "Training at Epoch 9 iteration 500 with loss 0.44381. Total time 0.63222 hours\n",
      "Training at Epoch 9 iteration 600 with loss 0.36855. Total time 0.6425 hours\n",
      "Validation at Epoch 9 with loss:0.59917, MSE: 0.43229 , Pearson Correlation: 0.72000 with p-value: 0.00E+00 , Concordance Index: 0.77542\n",
      "Training at Epoch 10 iteration 0 with loss 0.52580. Total time 0.65527 hours\n",
      "Training at Epoch 10 iteration 100 with loss 0.37823. Total time 0.66583 hours\n",
      "Training at Epoch 10 iteration 200 with loss 0.36539. Total time 0.67638 hours\n",
      "Training at Epoch 10 iteration 300 with loss 0.53217. Total time 0.68666 hours\n",
      "Training at Epoch 10 iteration 400 with loss 0.34222. Total time 0.69694 hours\n",
      "Training at Epoch 10 iteration 500 with loss 0.51725. Total time 0.70694 hours\n",
      "Training at Epoch 10 iteration 600 with loss 0.43864. Total time 0.71722 hours\n",
      "Validation at Epoch 10 with loss:0.37746, MSE: 0.33585 , Pearson Correlation: 0.72366 with p-value: 0.00E+00 , Concordance Index: 0.77952\n",
      "Training at Epoch 11 iteration 0 with loss 0.43252. Total time 0.73 hours\n",
      "Training at Epoch 11 iteration 100 with loss 0.46388. Total time 0.74027 hours\n",
      "Training at Epoch 11 iteration 200 with loss 0.56696. Total time 0.75027 hours\n",
      "Training at Epoch 11 iteration 300 with loss 0.46984. Total time 0.76055 hours\n",
      "Training at Epoch 11 iteration 400 with loss 0.40142. Total time 0.77055 hours\n",
      "Training at Epoch 11 iteration 500 with loss 0.52726. Total time 0.78083 hours\n",
      "Training at Epoch 11 iteration 600 with loss 0.39906. Total time 0.79111 hours\n",
      "Validation at Epoch 11 with loss:0.20918, MSE: 0.34932 , Pearson Correlation: 0.71803 with p-value: 0.00E+00 , Concordance Index: 0.78147\n",
      "Training at Epoch 12 iteration 0 with loss 0.41826. Total time 0.80388 hours\n",
      "Training at Epoch 12 iteration 100 with loss 0.37013. Total time 0.81388 hours\n",
      "Training at Epoch 12 iteration 200 with loss 0.46632. Total time 0.82416 hours\n",
      "Training at Epoch 12 iteration 300 with loss 0.38685. Total time 0.83416 hours\n",
      "Training at Epoch 12 iteration 400 with loss 0.38261. Total time 0.84416 hours\n",
      "Training at Epoch 12 iteration 500 with loss 0.41186. Total time 0.85444 hours\n",
      "Training at Epoch 12 iteration 600 with loss 0.37587. Total time 0.86472 hours\n",
      "Validation at Epoch 12 with loss:0.20966, MSE: 0.33877 , Pearson Correlation: 0.74160 with p-value: 0.00E+00 , Concordance Index: 0.78888\n",
      "Training at Epoch 13 iteration 0 with loss 0.32059. Total time 0.87777 hours\n",
      "Training at Epoch 13 iteration 100 with loss 0.37934. Total time 0.88833 hours\n",
      "Training at Epoch 13 iteration 200 with loss 0.35441. Total time 0.89861 hours\n",
      "Training at Epoch 13 iteration 300 with loss 0.34917. Total time 0.90916 hours\n",
      "Training at Epoch 13 iteration 400 with loss 0.36739. Total time 0.91944 hours\n",
      "Training at Epoch 13 iteration 500 with loss 0.43139. Total time 0.92972 hours\n",
      "Training at Epoch 13 iteration 600 with loss 0.37158. Total time 0.94 hours\n",
      "Validation at Epoch 13 with loss:0.31354, MSE: 0.33371 , Pearson Correlation: 0.74597 with p-value: 0.00E+00 , Concordance Index: 0.79613\n",
      "Training at Epoch 14 iteration 0 with loss 0.41972. Total time 0.95333 hours\n",
      "Training at Epoch 14 iteration 100 with loss 0.55094. Total time 0.96361 hours\n",
      "Training at Epoch 14 iteration 200 with loss 0.30917. Total time 0.97416 hours\n",
      "Training at Epoch 14 iteration 300 with loss 0.36994. Total time 0.98444 hours\n",
      "Training at Epoch 14 iteration 400 with loss 0.31409. Total time 0.99472 hours\n",
      "Training at Epoch 14 iteration 500 with loss 0.29798. Total time 1.00527 hours\n",
      "Training at Epoch 14 iteration 600 with loss 0.44294. Total time 1.01555 hours\n",
      "Validation at Epoch 14 with loss:0.51774, MSE: 0.30720 , Pearson Correlation: 0.75148 with p-value: 0.00E+00 , Concordance Index: 0.80160\n",
      "Training at Epoch 15 iteration 0 with loss 0.44963. Total time 1.02861 hours\n",
      "Training at Epoch 15 iteration 100 with loss 0.32984. Total time 1.03888 hours\n",
      "Training at Epoch 15 iteration 200 with loss 0.41664. Total time 1.04944 hours\n",
      "Training at Epoch 15 iteration 300 with loss 0.75221. Total time 1.06 hours\n",
      "Training at Epoch 15 iteration 400 with loss 0.31785. Total time 1.07027 hours\n",
      "Training at Epoch 15 iteration 500 with loss 0.43035. Total time 1.08083 hours\n",
      "Training at Epoch 15 iteration 600 with loss 0.33353. Total time 1.09083 hours\n",
      "Validation at Epoch 15 with loss:0.43216, MSE: 0.31873 , Pearson Correlation: 0.74386 with p-value: 0.00E+00 , Concordance Index: 0.79012\n",
      "Training at Epoch 16 iteration 0 with loss 0.35849. Total time 1.10361 hours\n",
      "Training at Epoch 16 iteration 100 with loss 0.29608. Total time 1.11361 hours\n",
      "Training at Epoch 16 iteration 200 with loss 0.24417. Total time 1.12388 hours\n",
      "Training at Epoch 16 iteration 300 with loss 0.44038. Total time 1.13388 hours\n",
      "Training at Epoch 16 iteration 400 with loss 0.35676. Total time 1.14416 hours\n",
      "Training at Epoch 16 iteration 500 with loss 0.30583. Total time 1.15416 hours\n",
      "Training at Epoch 16 iteration 600 with loss 0.35348. Total time 1.16444 hours\n",
      "Validation at Epoch 16 with loss:0.42319, MSE: 0.33097 , Pearson Correlation: 0.75748 with p-value: 0.00E+00 , Concordance Index: 0.80265\n",
      "Training at Epoch 17 iteration 0 with loss 0.36057. Total time 1.17722 hours\n",
      "Training at Epoch 17 iteration 100 with loss 0.37389. Total time 1.18777 hours\n",
      "Training at Epoch 17 iteration 200 with loss 0.57269. Total time 1.19805 hours\n",
      "Training at Epoch 17 iteration 300 with loss 0.25321. Total time 1.20861 hours\n",
      "Training at Epoch 17 iteration 400 with loss 0.27263. Total time 1.21888 hours\n",
      "Training at Epoch 17 iteration 500 with loss 0.31608. Total time 1.22944 hours\n",
      "Training at Epoch 17 iteration 600 with loss 0.30937. Total time 1.23972 hours\n",
      "Validation at Epoch 17 with loss:0.25852, MSE: 0.30599 , Pearson Correlation: 0.76576 with p-value: 0.00E+00 , Concordance Index: 0.80477\n",
      "Training at Epoch 18 iteration 0 with loss 0.26915. Total time 1.2525 hours\n",
      "Training at Epoch 18 iteration 100 with loss 0.37705. Total time 1.2625 hours\n",
      "Training at Epoch 18 iteration 200 with loss 0.43875. Total time 1.27277 hours\n",
      "Training at Epoch 18 iteration 300 with loss 0.32412. Total time 1.28277 hours\n",
      "Training at Epoch 18 iteration 400 with loss 0.41788. Total time 1.29277 hours\n",
      "Training at Epoch 18 iteration 500 with loss 0.54366. Total time 1.30277 hours\n",
      "Training at Epoch 18 iteration 600 with loss 0.28763. Total time 1.31305 hours\n",
      "Validation at Epoch 18 with loss:0.42908, MSE: 0.29272 , Pearson Correlation: 0.76637 with p-value: 0.00E+00 , Concordance Index: 0.79841\n",
      "Training at Epoch 19 iteration 0 with loss 0.43131. Total time 1.32583 hours\n",
      "Training at Epoch 19 iteration 100 with loss 0.31335. Total time 1.33583 hours\n",
      "Training at Epoch 19 iteration 200 with loss 0.48836. Total time 1.34583 hours\n",
      "Training at Epoch 19 iteration 300 with loss 0.42017. Total time 1.35611 hours\n",
      "Training at Epoch 19 iteration 400 with loss 0.37713. Total time 1.36611 hours\n",
      "Training at Epoch 19 iteration 500 with loss 0.26408. Total time 1.37611 hours\n",
      "Training at Epoch 19 iteration 600 with loss 0.29168. Total time 1.38611 hours\n",
      "Validation at Epoch 19 with loss:0.52372, MSE: 0.27974 , Pearson Correlation: 0.78386 with p-value: 0.00E+00 , Concordance Index: 0.80996\n",
      "Training at Epoch 20 iteration 0 with loss 0.31779. Total time 1.39888 hours\n",
      "Training at Epoch 20 iteration 100 with loss 0.46221. Total time 1.40861 hours\n",
      "Training at Epoch 20 iteration 200 with loss 0.43156. Total time 1.41861 hours\n",
      "Training at Epoch 20 iteration 300 with loss 0.39877. Total time 1.42833 hours\n",
      "Training at Epoch 20 iteration 400 with loss 0.52256. Total time 1.43833 hours\n",
      "Training at Epoch 20 iteration 500 with loss 0.32571. Total time 1.44805 hours\n",
      "Training at Epoch 20 iteration 600 with loss 0.26273. Total time 1.45805 hours\n",
      "Validation at Epoch 20 with loss:0.23175, MSE: 0.29628 , Pearson Correlation: 0.76879 with p-value: 0.00E+00 , Concordance Index: 0.80423\n",
      "Training at Epoch 21 iteration 0 with loss 0.23587. Total time 1.47055 hours\n",
      "Training at Epoch 21 iteration 100 with loss 0.30101. Total time 1.48055 hours\n",
      "Training at Epoch 21 iteration 200 with loss 0.52531. Total time 1.49027 hours\n",
      "Training at Epoch 21 iteration 300 with loss 0.26754. Total time 1.50027 hours\n",
      "Training at Epoch 21 iteration 400 with loss 0.36134. Total time 1.51 hours\n",
      "Training at Epoch 21 iteration 500 with loss 0.32049. Total time 1.52 hours\n",
      "Training at Epoch 21 iteration 600 with loss 0.36137. Total time 1.52972 hours\n",
      "Validation at Epoch 21 with loss:0.26184, MSE: 0.31899 , Pearson Correlation: 0.77366 with p-value: 0.00E+00 , Concordance Index: 0.81037\n",
      "Training at Epoch 22 iteration 0 with loss 0.45482. Total time 1.5425 hours\n",
      "Training at Epoch 22 iteration 100 with loss 0.44546. Total time 1.55222 hours\n",
      "Training at Epoch 22 iteration 200 with loss 0.37021. Total time 1.56222 hours\n",
      "Training at Epoch 22 iteration 300 with loss 0.33145. Total time 1.57194 hours\n",
      "Training at Epoch 22 iteration 400 with loss 0.26095. Total time 1.58194 hours\n",
      "Training at Epoch 22 iteration 500 with loss 0.37625. Total time 1.59166 hours\n",
      "Training at Epoch 22 iteration 600 with loss 0.32778. Total time 1.60166 hours\n",
      "Validation at Epoch 22 with loss:0.26954, MSE: 0.28264 , Pearson Correlation: 0.77387 with p-value: 0.00E+00 , Concordance Index: 0.80939\n",
      "Training at Epoch 23 iteration 0 with loss 0.29642. Total time 1.61444 hours\n",
      "Training at Epoch 23 iteration 100 with loss 0.25683. Total time 1.62416 hours\n",
      "Training at Epoch 23 iteration 200 with loss 0.37065. Total time 1.63416 hours\n",
      "Training at Epoch 23 iteration 300 with loss 0.42716. Total time 1.64388 hours\n",
      "Training at Epoch 23 iteration 400 with loss 0.33574. Total time 1.65388 hours\n",
      "Training at Epoch 23 iteration 500 with loss 0.36386. Total time 1.66361 hours\n",
      "Training at Epoch 23 iteration 600 with loss 0.26003. Total time 1.67361 hours\n",
      "Validation at Epoch 23 with loss:0.32549, MSE: 0.27502 , Pearson Correlation: 0.78155 with p-value: 0.00E+00 , Concordance Index: 0.81054\n",
      "Training at Epoch 24 iteration 0 with loss 0.25177. Total time 1.68638 hours\n",
      "Training at Epoch 24 iteration 100 with loss 0.34219. Total time 1.69611 hours\n",
      "Training at Epoch 24 iteration 200 with loss 0.42535. Total time 1.70611 hours\n",
      "Training at Epoch 24 iteration 300 with loss 0.35244. Total time 1.71583 hours\n",
      "Training at Epoch 24 iteration 400 with loss 0.29174. Total time 1.72555 hours\n",
      "Training at Epoch 24 iteration 500 with loss 0.36287. Total time 1.73555 hours\n",
      "Training at Epoch 24 iteration 600 with loss 0.30644. Total time 1.74527 hours\n",
      "Validation at Epoch 24 with loss:0.24073, MSE: 0.28293 , Pearson Correlation: 0.78023 with p-value: 0.00E+00 , Concordance Index: 0.81379\n",
      "Training at Epoch 25 iteration 0 with loss 0.33427. Total time 1.75805 hours\n",
      "Training at Epoch 25 iteration 100 with loss 0.22219. Total time 1.76805 hours\n",
      "Training at Epoch 25 iteration 200 with loss 0.26504. Total time 1.77777 hours\n",
      "Training at Epoch 25 iteration 300 with loss 0.23029. Total time 1.78777 hours\n",
      "Training at Epoch 25 iteration 400 with loss 0.38775. Total time 1.7975 hours\n",
      "Training at Epoch 25 iteration 500 with loss 0.37402. Total time 1.8075 hours\n",
      "Training at Epoch 25 iteration 600 with loss 0.40297. Total time 1.81722 hours\n",
      "Validation at Epoch 25 with loss:0.45204, MSE: 0.26422 , Pearson Correlation: 0.79447 with p-value: 0.00E+00 , Concordance Index: 0.81797\n",
      "Training at Epoch 26 iteration 0 with loss 0.26017. Total time 1.83 hours\n",
      "Training at Epoch 26 iteration 100 with loss 0.24760. Total time 1.83972 hours\n",
      "Training at Epoch 26 iteration 200 with loss 0.29910. Total time 1.84972 hours\n",
      "Training at Epoch 26 iteration 300 with loss 0.33632. Total time 1.85944 hours\n",
      "Training at Epoch 26 iteration 400 with loss 0.33208. Total time 1.86944 hours\n",
      "Training at Epoch 26 iteration 500 with loss 0.37121. Total time 1.87916 hours\n",
      "Training at Epoch 26 iteration 600 with loss 0.36272. Total time 1.88916 hours\n",
      "Validation at Epoch 26 with loss:0.56679, MSE: 0.25704 , Pearson Correlation: 0.79766 with p-value: 0.00E+00 , Concordance Index: 0.81957\n",
      "Training at Epoch 27 iteration 0 with loss 0.23265. Total time 1.90194 hours\n",
      "Training at Epoch 27 iteration 100 with loss 0.41043. Total time 1.91166 hours\n",
      "Training at Epoch 27 iteration 200 with loss 0.34664. Total time 1.92138 hours\n",
      "Training at Epoch 27 iteration 300 with loss 0.27562. Total time 1.93138 hours\n",
      "Training at Epoch 27 iteration 400 with loss 0.24747. Total time 1.94111 hours\n",
      "Training at Epoch 27 iteration 500 with loss 0.24002. Total time 1.95111 hours\n",
      "Training at Epoch 27 iteration 600 with loss 0.31124. Total time 1.96083 hours\n",
      "Validation at Epoch 27 with loss:0.20042, MSE: 0.27727 , Pearson Correlation: 0.78406 with p-value: 0.00E+00 , Concordance Index: 0.81984\n",
      "Training at Epoch 28 iteration 0 with loss 0.17053. Total time 1.97361 hours\n",
      "Training at Epoch 28 iteration 100 with loss 0.30172. Total time 1.98361 hours\n",
      "Training at Epoch 28 iteration 200 with loss 0.27937. Total time 1.99333 hours\n",
      "Training at Epoch 28 iteration 300 with loss 0.21662. Total time 2.00333 hours\n",
      "Training at Epoch 28 iteration 400 with loss 0.30272. Total time 2.01305 hours\n",
      "Training at Epoch 28 iteration 500 with loss 0.51468. Total time 2.02305 hours\n",
      "Training at Epoch 28 iteration 600 with loss 0.28484. Total time 2.03277 hours\n",
      "Validation at Epoch 28 with loss:0.18610, MSE: 0.27487 , Pearson Correlation: 0.78537 with p-value: 0.00E+00 , Concordance Index: 0.80896\n",
      "Training at Epoch 29 iteration 0 with loss 0.27929. Total time 2.04555 hours\n",
      "Training at Epoch 29 iteration 100 with loss 0.28178. Total time 2.05555 hours\n",
      "Training at Epoch 29 iteration 200 with loss 0.26537. Total time 2.06527 hours\n",
      "Training at Epoch 29 iteration 300 with loss 0.32777. Total time 2.07527 hours\n",
      "Training at Epoch 29 iteration 400 with loss 0.31352. Total time 2.085 hours\n",
      "Training at Epoch 29 iteration 500 with loss 0.38258. Total time 2.095 hours\n",
      "Training at Epoch 29 iteration 600 with loss 0.40539. Total time 2.10472 hours\n",
      "Validation at Epoch 29 with loss:0.18075, MSE: 0.26481 , Pearson Correlation: 0.79679 with p-value: 0.00E+00 , Concordance Index: 0.82165\n",
      "Training at Epoch 30 iteration 0 with loss 0.24830. Total time 2.1175 hours\n",
      "Training at Epoch 30 iteration 100 with loss 0.36519. Total time 2.1275 hours\n",
      "Training at Epoch 30 iteration 200 with loss 0.26109. Total time 2.13722 hours\n",
      "Training at Epoch 30 iteration 300 with loss 0.25053. Total time 2.14722 hours\n",
      "Training at Epoch 30 iteration 400 with loss 0.40742. Total time 2.15694 hours\n",
      "Training at Epoch 30 iteration 500 with loss 0.26562. Total time 2.16694 hours\n",
      "Training at Epoch 30 iteration 600 with loss 0.18379. Total time 2.17694 hours\n",
      "Validation at Epoch 30 with loss:0.27485, MSE: 0.26694 , Pearson Correlation: 0.79858 with p-value: 0.00E+00 , Concordance Index: 0.81778\n",
      "Training at Epoch 31 iteration 0 with loss 0.38802. Total time 2.19 hours\n",
      "Training at Epoch 31 iteration 100 with loss 0.29691. Total time 2.2 hours\n",
      "Training at Epoch 31 iteration 200 with loss 0.47229. Total time 2.21027 hours\n",
      "Training at Epoch 31 iteration 300 with loss 0.30777. Total time 2.22027 hours\n",
      "Training at Epoch 31 iteration 400 with loss 0.29193. Total time 2.23027 hours\n",
      "Training at Epoch 31 iteration 500 with loss 0.27986. Total time 2.24055 hours\n",
      "Training at Epoch 31 iteration 600 with loss 0.30009. Total time 2.25055 hours\n",
      "Validation at Epoch 31 with loss:0.41845, MSE: 0.24821 , Pearson Correlation: 0.80976 with p-value: 0.00E+00 , Concordance Index: 0.82392\n",
      "Training at Epoch 32 iteration 0 with loss 0.22424. Total time 2.26361 hours\n",
      "Training at Epoch 32 iteration 100 with loss 0.26291. Total time 2.27361 hours\n",
      "Training at Epoch 32 iteration 200 with loss 0.31679. Total time 2.28388 hours\n",
      "Training at Epoch 32 iteration 300 with loss 0.28754. Total time 2.29388 hours\n",
      "Training at Epoch 32 iteration 400 with loss 0.33778. Total time 2.30416 hours\n",
      "Training at Epoch 32 iteration 500 with loss 0.30261. Total time 2.31416 hours\n",
      "Training at Epoch 32 iteration 600 with loss 0.30386. Total time 2.32444 hours\n",
      "Validation at Epoch 32 with loss:0.31903, MSE: 0.24712 , Pearson Correlation: 0.80571 with p-value: 0.00E+00 , Concordance Index: 0.82330\n",
      "Training at Epoch 33 iteration 0 with loss 0.32378. Total time 2.33722 hours\n",
      "Training at Epoch 33 iteration 100 with loss 0.23564. Total time 2.34777 hours\n",
      "Training at Epoch 33 iteration 200 with loss 0.30604. Total time 2.35777 hours\n",
      "Training at Epoch 33 iteration 300 with loss 0.32682. Total time 2.36805 hours\n",
      "Training at Epoch 33 iteration 400 with loss 0.34625. Total time 2.37805 hours\n",
      "Training at Epoch 33 iteration 500 with loss 0.23764. Total time 2.38833 hours\n",
      "Training at Epoch 33 iteration 600 with loss 0.28457. Total time 2.39833 hours\n",
      "Validation at Epoch 33 with loss:0.57737, MSE: 0.25758 , Pearson Correlation: 0.80822 with p-value: 0.00E+00 , Concordance Index: 0.82521\n",
      "Training at Epoch 34 iteration 0 with loss 0.27101. Total time 2.41138 hours\n",
      "Training at Epoch 34 iteration 100 with loss 0.28425. Total time 2.42138 hours\n",
      "Training at Epoch 34 iteration 200 with loss 0.27444. Total time 2.43138 hours\n",
      "Training at Epoch 34 iteration 300 with loss 0.25198. Total time 2.44166 hours\n",
      "Training at Epoch 34 iteration 400 with loss 0.25799. Total time 2.45166 hours\n",
      "Training at Epoch 34 iteration 500 with loss 0.25431. Total time 2.46166 hours\n",
      "Training at Epoch 34 iteration 600 with loss 0.33612. Total time 2.47194 hours\n",
      "Validation at Epoch 34 with loss:0.20956, MSE: 0.24916 , Pearson Correlation: 0.81127 with p-value: 0.00E+00 , Concordance Index: 0.82701\n",
      "Training at Epoch 35 iteration 0 with loss 0.20214. Total time 2.48472 hours\n",
      "Training at Epoch 35 iteration 100 with loss 0.28504. Total time 2.49472 hours\n",
      "Training at Epoch 35 iteration 200 with loss 0.18717. Total time 2.505 hours\n",
      "Training at Epoch 35 iteration 300 with loss 0.30671. Total time 2.515 hours\n",
      "Training at Epoch 35 iteration 400 with loss 0.34743. Total time 2.52527 hours\n",
      "Training at Epoch 35 iteration 500 with loss 0.18984. Total time 2.53527 hours\n",
      "Training at Epoch 35 iteration 600 with loss 0.24501. Total time 2.54555 hours\n",
      "Validation at Epoch 35 with loss:0.28516, MSE: 0.26773 , Pearson Correlation: 0.81115 with p-value: 0.00E+00 , Concordance Index: 0.82601\n",
      "Training at Epoch 36 iteration 0 with loss 0.30678. Total time 2.55861 hours\n",
      "Training at Epoch 36 iteration 100 with loss 0.29007. Total time 2.56861 hours\n",
      "Training at Epoch 36 iteration 200 with loss 0.25431. Total time 2.57888 hours\n",
      "Training at Epoch 36 iteration 300 with loss 0.28567. Total time 2.58888 hours\n",
      "Training at Epoch 36 iteration 400 with loss 0.21257. Total time 2.59916 hours\n",
      "Training at Epoch 36 iteration 500 with loss 0.24844. Total time 2.60944 hours\n",
      "Training at Epoch 36 iteration 600 with loss 0.32267. Total time 2.61944 hours\n",
      "Validation at Epoch 36 with loss:0.34496, MSE: 0.31656 , Pearson Correlation: 0.81522 with p-value: 0.00E+00 , Concordance Index: 0.83192\n",
      "Training at Epoch 37 iteration 0 with loss 0.34385. Total time 2.6325 hours\n",
      "Training at Epoch 37 iteration 100 with loss 0.30284. Total time 2.6425 hours\n",
      "Training at Epoch 37 iteration 200 with loss 0.21309. Total time 2.6525 hours\n",
      "Training at Epoch 37 iteration 300 with loss 0.24427. Total time 2.6625 hours\n",
      "Training at Epoch 37 iteration 400 with loss 0.28273. Total time 2.6725 hours\n",
      "Training at Epoch 37 iteration 500 with loss 0.21432. Total time 2.68277 hours\n",
      "Training at Epoch 37 iteration 600 with loss 0.32787. Total time 2.69277 hours\n",
      "Validation at Epoch 37 with loss:0.18100, MSE: 0.24121 , Pearson Correlation: 0.81638 with p-value: 0.00E+00 , Concordance Index: 0.82936\n",
      "Training at Epoch 38 iteration 0 with loss 0.17570. Total time 2.70555 hours\n",
      "Training at Epoch 38 iteration 100 with loss 0.25094. Total time 2.71583 hours\n",
      "Training at Epoch 38 iteration 200 with loss 0.33290. Total time 2.72583 hours\n",
      "Training at Epoch 38 iteration 300 with loss 0.25750. Total time 2.73583 hours\n",
      "Training at Epoch 38 iteration 400 with loss 0.26786. Total time 2.74583 hours\n",
      "Training at Epoch 38 iteration 500 with loss 0.23513. Total time 2.75583 hours\n",
      "Training at Epoch 38 iteration 600 with loss 0.29231. Total time 2.76611 hours\n",
      "Validation at Epoch 38 with loss:0.17594, MSE: 0.24266 , Pearson Correlation: 0.81089 with p-value: 0.00E+00 , Concordance Index: 0.82688\n",
      "Training at Epoch 39 iteration 0 with loss 0.19032. Total time 2.77888 hours\n",
      "Training at Epoch 39 iteration 100 with loss 0.23143. Total time 2.78888 hours\n",
      "Training at Epoch 39 iteration 200 with loss 0.20598. Total time 2.79888 hours\n",
      "Training at Epoch 39 iteration 300 with loss 0.33546. Total time 2.80916 hours\n",
      "Training at Epoch 39 iteration 400 with loss 0.22195. Total time 2.81916 hours\n",
      "Training at Epoch 39 iteration 500 with loss 0.27367. Total time 2.82916 hours\n",
      "Training at Epoch 39 iteration 600 with loss 0.30158. Total time 2.83944 hours\n",
      "Validation at Epoch 39 with loss:0.12015, MSE: 0.24510 , Pearson Correlation: 0.81626 with p-value: 0.00E+00 , Concordance Index: 0.82984\n",
      "Training at Epoch 40 iteration 0 with loss 0.20728. Total time 2.85222 hours\n",
      "Training at Epoch 40 iteration 100 with loss 0.25326. Total time 2.8625 hours\n",
      "Training at Epoch 40 iteration 200 with loss 0.14412. Total time 2.8725 hours\n",
      "Training at Epoch 40 iteration 300 with loss 0.19058. Total time 2.88277 hours\n",
      "Training at Epoch 40 iteration 400 with loss 0.22250. Total time 2.89305 hours\n",
      "Training at Epoch 40 iteration 500 with loss 0.21281. Total time 2.90333 hours\n",
      "Training at Epoch 40 iteration 600 with loss 0.26334. Total time 2.91333 hours\n",
      "Validation at Epoch 40 with loss:0.24761, MSE: 0.23917 , Pearson Correlation: 0.81445 with p-value: 0.00E+00 , Concordance Index: 0.83035\n",
      "Training at Epoch 41 iteration 0 with loss 0.26745. Total time 2.92638 hours\n",
      "Training at Epoch 41 iteration 100 with loss 0.35497. Total time 2.93638 hours\n",
      "Training at Epoch 41 iteration 200 with loss 0.18831. Total time 2.94638 hours\n",
      "Training at Epoch 41 iteration 300 with loss 0.21081. Total time 2.95638 hours\n",
      "Training at Epoch 41 iteration 400 with loss 0.27202. Total time 2.96666 hours\n",
      "Training at Epoch 41 iteration 500 with loss 0.25674. Total time 2.97666 hours\n",
      "Training at Epoch 41 iteration 600 with loss 0.26088. Total time 2.98666 hours\n",
      "Validation at Epoch 41 with loss:0.28219, MSE: 0.22552 , Pearson Correlation: 0.82530 with p-value: 0.00E+00 , Concordance Index: 0.83280\n",
      "Training at Epoch 42 iteration 0 with loss 0.18803. Total time 2.99972 hours\n",
      "Training at Epoch 42 iteration 100 with loss 0.22615. Total time 3.00972 hours\n",
      "Training at Epoch 42 iteration 200 with loss 0.31884. Total time 3.01972 hours\n",
      "Training at Epoch 42 iteration 300 with loss 0.19242. Total time 3.02972 hours\n",
      "Training at Epoch 42 iteration 400 with loss 0.27968. Total time 3.03972 hours\n",
      "Training at Epoch 42 iteration 500 with loss 0.24257. Total time 3.05 hours\n",
      "Training at Epoch 42 iteration 600 with loss 0.20470. Total time 3.06 hours\n",
      "Validation at Epoch 42 with loss:0.18364, MSE: 0.23639 , Pearson Correlation: 0.81931 with p-value: 0.00E+00 , Concordance Index: 0.83279\n",
      "Training at Epoch 43 iteration 0 with loss 0.20159. Total time 3.07305 hours\n",
      "Training at Epoch 43 iteration 100 with loss 0.23580. Total time 3.08305 hours\n",
      "Training at Epoch 43 iteration 200 with loss 0.21573. Total time 3.09333 hours\n",
      "Training at Epoch 43 iteration 300 with loss 0.23605. Total time 3.10361 hours\n",
      "Training at Epoch 43 iteration 400 with loss 0.20745. Total time 3.11361 hours\n",
      "Training at Epoch 43 iteration 500 with loss 0.30872. Total time 3.12388 hours\n",
      "Training at Epoch 43 iteration 600 with loss 0.24586. Total time 3.13416 hours\n",
      "Validation at Epoch 43 with loss:0.18122, MSE: 0.23804 , Pearson Correlation: 0.81644 with p-value: 0.00E+00 , Concordance Index: 0.83097\n",
      "Training at Epoch 44 iteration 0 with loss 0.28409. Total time 3.1475 hours\n",
      "Training at Epoch 44 iteration 100 with loss 0.19851. Total time 3.1575 hours\n",
      "Training at Epoch 44 iteration 200 with loss 0.28261. Total time 3.16777 hours\n",
      "Training at Epoch 44 iteration 300 with loss 0.15057. Total time 3.17777 hours\n",
      "Training at Epoch 44 iteration 400 with loss 0.34079. Total time 3.18805 hours\n",
      "Training at Epoch 44 iteration 500 with loss 0.25470. Total time 3.19833 hours\n",
      "Training at Epoch 44 iteration 600 with loss 0.20736. Total time 3.20888 hours\n",
      "Validation at Epoch 44 with loss:0.58237, MSE: 0.24019 , Pearson Correlation: 0.82242 with p-value: 0.00E+00 , Concordance Index: 0.83191\n",
      "Training at Epoch 45 iteration 0 with loss 0.21705. Total time 3.22194 hours\n",
      "Training at Epoch 45 iteration 100 with loss 0.28456. Total time 3.23194 hours\n",
      "Training at Epoch 45 iteration 200 with loss 0.24872. Total time 3.24222 hours\n",
      "Training at Epoch 45 iteration 300 with loss 0.21530. Total time 3.25222 hours\n",
      "Training at Epoch 45 iteration 400 with loss 0.28297. Total time 3.26222 hours\n",
      "Training at Epoch 45 iteration 500 with loss 0.18207. Total time 3.2725 hours\n",
      "Training at Epoch 45 iteration 600 with loss 0.22078. Total time 3.2825 hours\n",
      "Validation at Epoch 45 with loss:0.31184, MSE: 0.23697 , Pearson Correlation: 0.82302 with p-value: 0.00E+00 , Concordance Index: 0.83685\n",
      "Training at Epoch 46 iteration 0 with loss 0.31853. Total time 3.29555 hours\n",
      "Training at Epoch 46 iteration 100 with loss 0.21075. Total time 3.30555 hours\n",
      "Training at Epoch 46 iteration 200 with loss 0.24444. Total time 3.31555 hours\n",
      "Training at Epoch 46 iteration 300 with loss 0.19204. Total time 3.32583 hours\n",
      "Training at Epoch 46 iteration 400 with loss 0.21867. Total time 3.33583 hours\n",
      "Training at Epoch 46 iteration 500 with loss 0.26735. Total time 3.34611 hours\n",
      "Training at Epoch 46 iteration 600 with loss 0.27087. Total time 3.35611 hours\n",
      "Validation at Epoch 46 with loss:0.23780, MSE: 0.22646 , Pearson Correlation: 0.82713 with p-value: 0.00E+00 , Concordance Index: 0.83841\n",
      "Training at Epoch 47 iteration 0 with loss 0.22065. Total time 3.36888 hours\n",
      "Training at Epoch 47 iteration 100 with loss 0.21851. Total time 3.37916 hours\n",
      "Training at Epoch 47 iteration 200 with loss 0.24251. Total time 3.38916 hours\n",
      "Training at Epoch 47 iteration 300 with loss 0.21818. Total time 3.39916 hours\n",
      "Training at Epoch 47 iteration 400 with loss 0.19525. Total time 3.40944 hours\n",
      "Training at Epoch 47 iteration 500 with loss 0.22146. Total time 3.41972 hours\n",
      "Training at Epoch 47 iteration 600 with loss 0.24375. Total time 3.42972 hours\n",
      "Validation at Epoch 47 with loss:0.11494, MSE: 0.22858 , Pearson Correlation: 0.82180 with p-value: 0.00E+00 , Concordance Index: 0.83257\n",
      "Training at Epoch 48 iteration 0 with loss 0.22155. Total time 3.44277 hours\n",
      "Training at Epoch 48 iteration 100 with loss 0.21646. Total time 3.45277 hours\n",
      "Training at Epoch 48 iteration 200 with loss 0.26503. Total time 3.46305 hours\n",
      "Training at Epoch 48 iteration 300 with loss 0.28707. Total time 3.47305 hours\n",
      "Training at Epoch 48 iteration 400 with loss 0.14750. Total time 3.48305 hours\n",
      "Training at Epoch 48 iteration 500 with loss 0.24763. Total time 3.49277 hours\n",
      "Training at Epoch 48 iteration 600 with loss 0.27441. Total time 3.50305 hours\n",
      "Validation at Epoch 48 with loss:0.28676, MSE: 0.23009 , Pearson Correlation: 0.82306 with p-value: 0.00E+00 , Concordance Index: 0.83354\n",
      "Training at Epoch 49 iteration 0 with loss 0.27882. Total time 3.51611 hours\n",
      "Training at Epoch 49 iteration 100 with loss 0.26129. Total time 3.52638 hours\n",
      "Training at Epoch 49 iteration 200 with loss 0.22346. Total time 3.53666 hours\n",
      "Training at Epoch 49 iteration 300 with loss 0.16281. Total time 3.54694 hours\n",
      "Training at Epoch 49 iteration 400 with loss 0.18910. Total time 3.55694 hours\n",
      "Training at Epoch 49 iteration 500 with loss 0.26052. Total time 3.56694 hours\n",
      "Training at Epoch 49 iteration 600 with loss 0.23957. Total time 3.57722 hours\n",
      "Validation at Epoch 49 with loss:0.26876, MSE: 0.22982 , Pearson Correlation: 0.82650 with p-value: 0.00E+00 , Concordance Index: 0.83727\n",
      "Training at Epoch 50 iteration 0 with loss 0.19354. Total time 3.59027 hours\n",
      "Training at Epoch 50 iteration 100 with loss 0.21817. Total time 3.60083 hours\n",
      "Training at Epoch 50 iteration 200 with loss 0.27950. Total time 3.61138 hours\n",
      "Training at Epoch 50 iteration 300 with loss 0.26775. Total time 3.62194 hours\n",
      "Training at Epoch 50 iteration 400 with loss 0.21305. Total time 3.63194 hours\n",
      "Training at Epoch 50 iteration 500 with loss 0.16016. Total time 3.64222 hours\n",
      "Training at Epoch 50 iteration 600 with loss 0.20568. Total time 3.65222 hours\n",
      "Validation at Epoch 50 with loss:0.29816, MSE: 0.22060 , Pearson Correlation: 0.82888 with p-value: 0.00E+00 , Concordance Index: 0.83717\n",
      "Training at Epoch 51 iteration 0 with loss 0.29683. Total time 3.66527 hours\n",
      "Training at Epoch 51 iteration 100 with loss 0.17673. Total time 3.67555 hours\n",
      "Training at Epoch 51 iteration 200 with loss 0.16678. Total time 3.68583 hours\n",
      "Training at Epoch 51 iteration 300 with loss 0.22761. Total time 3.69611 hours\n",
      "Training at Epoch 51 iteration 400 with loss 0.20271. Total time 3.70638 hours\n",
      "Training at Epoch 51 iteration 500 with loss 0.24287. Total time 3.71666 hours\n",
      "Training at Epoch 51 iteration 600 with loss 0.15371. Total time 3.72694 hours\n",
      "Validation at Epoch 51 with loss:0.23073, MSE: 0.22213 , Pearson Correlation: 0.82907 with p-value: 0.00E+00 , Concordance Index: 0.83835\n",
      "Training at Epoch 52 iteration 0 with loss 0.31074. Total time 3.74 hours\n",
      "Training at Epoch 52 iteration 100 with loss 0.22751. Total time 3.75 hours\n",
      "Training at Epoch 52 iteration 200 with loss 0.21269. Total time 3.76 hours\n",
      "Training at Epoch 52 iteration 300 with loss 0.17581. Total time 3.77027 hours\n",
      "Training at Epoch 52 iteration 400 with loss 0.30646. Total time 3.78027 hours\n",
      "Training at Epoch 52 iteration 500 with loss 0.33837. Total time 3.79027 hours\n",
      "Training at Epoch 52 iteration 600 with loss 0.22185. Total time 3.80055 hours\n",
      "Validation at Epoch 52 with loss:0.34105, MSE: 0.22964 , Pearson Correlation: 0.82465 with p-value: 0.00E+00 , Concordance Index: 0.83540\n",
      "Training at Epoch 53 iteration 0 with loss 0.27647. Total time 3.81361 hours\n",
      "Training at Epoch 53 iteration 100 with loss 0.26890. Total time 3.82361 hours\n",
      "Training at Epoch 53 iteration 200 with loss 0.21167. Total time 3.83444 hours\n",
      "Training at Epoch 53 iteration 300 with loss 0.25321. Total time 3.84694 hours\n",
      "Training at Epoch 53 iteration 400 with loss 0.20892. Total time 3.85944 hours\n",
      "Training at Epoch 53 iteration 500 with loss 0.20367. Total time 3.87194 hours\n",
      "Training at Epoch 53 iteration 600 with loss 0.30625. Total time 3.8825 hours\n",
      "Validation at Epoch 53 with loss:0.15359, MSE: 0.22049 , Pearson Correlation: 0.83009 with p-value: 0.00E+00 , Concordance Index: 0.84211\n",
      "Training at Epoch 54 iteration 0 with loss 0.14833. Total time 3.89555 hours\n",
      "Training at Epoch 54 iteration 100 with loss 0.29624. Total time 3.90555 hours\n",
      "Training at Epoch 54 iteration 200 with loss 0.26496. Total time 3.91583 hours\n",
      "Training at Epoch 54 iteration 300 with loss 0.22695. Total time 3.92611 hours\n",
      "Training at Epoch 54 iteration 400 with loss 0.24439. Total time 3.93611 hours\n",
      "Training at Epoch 54 iteration 500 with loss 0.22737. Total time 3.94638 hours\n",
      "Training at Epoch 54 iteration 600 with loss 0.15487. Total time 3.95666 hours\n",
      "Validation at Epoch 54 with loss:0.08267, MSE: 0.23959 , Pearson Correlation: 0.82451 with p-value: 0.00E+00 , Concordance Index: 0.83882\n",
      "Training at Epoch 55 iteration 0 with loss 0.22146. Total time 3.96972 hours\n",
      "Training at Epoch 55 iteration 100 with loss 0.22034. Total time 3.98 hours\n",
      "Training at Epoch 55 iteration 200 with loss 0.16090. Total time 3.99027 hours\n",
      "Training at Epoch 55 iteration 300 with loss 0.22932. Total time 4.00027 hours\n",
      "Training at Epoch 55 iteration 400 with loss 0.20352. Total time 4.01027 hours\n",
      "Training at Epoch 55 iteration 500 with loss 0.20594. Total time 4.02055 hours\n",
      "Training at Epoch 55 iteration 600 with loss 0.18330. Total time 4.03083 hours\n",
      "Validation at Epoch 55 with loss:0.04946, MSE: 0.22989 , Pearson Correlation: 0.82336 with p-value: 0.00E+00 , Concordance Index: 0.83790\n",
      "Training at Epoch 56 iteration 0 with loss 0.18031. Total time 4.04361 hours\n",
      "Training at Epoch 56 iteration 100 with loss 0.28790. Total time 4.05361 hours\n",
      "Training at Epoch 56 iteration 200 with loss 0.18297. Total time 4.06388 hours\n",
      "Training at Epoch 56 iteration 300 with loss 0.20161. Total time 4.07388 hours\n",
      "Training at Epoch 56 iteration 400 with loss 0.26566. Total time 4.08416 hours\n",
      "Training at Epoch 56 iteration 500 with loss 0.23873. Total time 4.09416 hours\n",
      "Training at Epoch 56 iteration 600 with loss 0.23805. Total time 4.10444 hours\n",
      "Validation at Epoch 56 with loss:0.17704, MSE: 0.22422 , Pearson Correlation: 0.83160 with p-value: 0.00E+00 , Concordance Index: 0.84134\n",
      "Training at Epoch 57 iteration 0 with loss 0.23968. Total time 4.1175 hours\n",
      "Training at Epoch 57 iteration 100 with loss 0.23594. Total time 4.1275 hours\n",
      "Training at Epoch 57 iteration 200 with loss 0.18523. Total time 4.13777 hours\n",
      "Training at Epoch 57 iteration 300 with loss 0.18579. Total time 4.14777 hours\n",
      "Training at Epoch 57 iteration 400 with loss 0.17338. Total time 4.15777 hours\n",
      "Training at Epoch 57 iteration 500 with loss 0.18507. Total time 4.16805 hours\n",
      "Training at Epoch 57 iteration 600 with loss 0.18603. Total time 4.17833 hours\n",
      "Validation at Epoch 57 with loss:0.28660, MSE: 0.23394 , Pearson Correlation: 0.82796 with p-value: 0.00E+00 , Concordance Index: 0.84167\n",
      "Training at Epoch 58 iteration 0 with loss 0.26479. Total time 4.19138 hours\n",
      "Training at Epoch 58 iteration 100 with loss 0.22530. Total time 4.20166 hours\n",
      "Training at Epoch 58 iteration 200 with loss 0.17628. Total time 4.21166 hours\n",
      "Training at Epoch 58 iteration 300 with loss 0.15410. Total time 4.22166 hours\n",
      "Training at Epoch 58 iteration 400 with loss 0.19047. Total time 4.23138 hours\n",
      "Training at Epoch 58 iteration 500 with loss 0.16524. Total time 4.24138 hours\n",
      "Training at Epoch 58 iteration 600 with loss 0.26087. Total time 4.25138 hours\n",
      "Validation at Epoch 58 with loss:0.30140, MSE: 0.21518 , Pearson Correlation: 0.83579 with p-value: 0.00E+00 , Concordance Index: 0.84305\n",
      "Training at Epoch 59 iteration 0 with loss 0.21846. Total time 4.26444 hours\n",
      "Training at Epoch 59 iteration 100 with loss 0.17127. Total time 4.27444 hours\n",
      "Training at Epoch 59 iteration 200 with loss 0.24063. Total time 4.28472 hours\n",
      "Training at Epoch 59 iteration 300 with loss 0.29266. Total time 4.295 hours\n",
      "Training at Epoch 59 iteration 400 with loss 0.21252. Total time 4.305 hours\n",
      "Training at Epoch 59 iteration 500 with loss 0.20915. Total time 4.315 hours\n",
      "Training at Epoch 59 iteration 600 with loss 0.16172. Total time 4.32527 hours\n",
      "Validation at Epoch 59 with loss:0.13945, MSE: 0.21562 , Pearson Correlation: 0.83379 with p-value: 0.00E+00 , Concordance Index: 0.84373\n",
      "Training at Epoch 60 iteration 0 with loss 0.22861. Total time 4.33805 hours\n",
      "Training at Epoch 60 iteration 100 with loss 0.28196. Total time 4.34833 hours\n",
      "Training at Epoch 60 iteration 200 with loss 0.24008. Total time 4.35861 hours\n",
      "Training at Epoch 60 iteration 300 with loss 0.18600. Total time 4.36861 hours\n",
      "Training at Epoch 60 iteration 400 with loss 0.29370. Total time 4.37888 hours\n",
      "Training at Epoch 60 iteration 500 with loss 0.26475. Total time 4.38888 hours\n",
      "Training at Epoch 60 iteration 600 with loss 0.22153. Total time 4.39888 hours\n",
      "Validation at Epoch 60 with loss:0.28405, MSE: 0.21348 , Pearson Correlation: 0.83490 with p-value: 0.00E+00 , Concordance Index: 0.84312\n",
      "Training at Epoch 61 iteration 0 with loss 0.15088. Total time 4.41194 hours\n",
      "Training at Epoch 61 iteration 100 with loss 0.24298. Total time 4.42222 hours\n",
      "Training at Epoch 61 iteration 200 with loss 0.24106. Total time 4.43222 hours\n",
      "Training at Epoch 61 iteration 300 with loss 0.23339. Total time 4.4425 hours\n",
      "Training at Epoch 61 iteration 400 with loss 0.20435. Total time 4.4525 hours\n",
      "Training at Epoch 61 iteration 500 with loss 0.20794. Total time 4.46277 hours\n",
      "Training at Epoch 61 iteration 600 with loss 0.24291. Total time 4.47305 hours\n",
      "Validation at Epoch 61 with loss:0.25792, MSE: 0.21309 , Pearson Correlation: 0.83585 with p-value: 0.00E+00 , Concordance Index: 0.84371\n",
      "Training at Epoch 62 iteration 0 with loss 0.14063. Total time 4.48611 hours\n",
      "Training at Epoch 62 iteration 100 with loss 0.18534. Total time 4.49638 hours\n",
      "Training at Epoch 62 iteration 200 with loss 0.20211. Total time 4.50638 hours\n",
      "Training at Epoch 62 iteration 300 with loss 0.18393. Total time 4.51666 hours\n",
      "Training at Epoch 62 iteration 400 with loss 0.23841. Total time 4.52666 hours\n",
      "Training at Epoch 62 iteration 500 with loss 0.23690. Total time 4.53694 hours\n",
      "Training at Epoch 62 iteration 600 with loss 0.19046. Total time 4.54694 hours\n",
      "Validation at Epoch 62 with loss:0.22368, MSE: 0.22532 , Pearson Correlation: 0.83413 with p-value: 0.00E+00 , Concordance Index: 0.84406\n",
      "Training at Epoch 63 iteration 0 with loss 0.25277. Total time 4.56 hours\n",
      "Training at Epoch 63 iteration 100 with loss 0.17548. Total time 4.57 hours\n",
      "Training at Epoch 63 iteration 200 with loss 0.16458. Total time 4.58027 hours\n",
      "Training at Epoch 63 iteration 300 with loss 0.19490. Total time 4.59027 hours\n",
      "Training at Epoch 63 iteration 400 with loss 0.14646. Total time 4.60055 hours\n",
      "Training at Epoch 63 iteration 500 with loss 0.14335. Total time 4.61055 hours\n",
      "Training at Epoch 63 iteration 600 with loss 0.15918. Total time 4.62083 hours\n",
      "Validation at Epoch 63 with loss:0.16170, MSE: 0.21739 , Pearson Correlation: 0.83363 with p-value: 0.00E+00 , Concordance Index: 0.84156\n",
      "Training at Epoch 64 iteration 0 with loss 0.16695. Total time 4.63388 hours\n",
      "Training at Epoch 64 iteration 100 with loss 0.19891. Total time 4.64388 hours\n",
      "Training at Epoch 64 iteration 200 with loss 0.14817. Total time 4.65416 hours\n",
      "Training at Epoch 64 iteration 300 with loss 0.23204. Total time 4.66416 hours\n",
      "Training at Epoch 64 iteration 400 with loss 0.24163. Total time 4.67444 hours\n",
      "Training at Epoch 64 iteration 500 with loss 0.08806. Total time 4.68444 hours\n",
      "Training at Epoch 64 iteration 600 with loss 0.19604. Total time 4.69472 hours\n",
      "Validation at Epoch 64 with loss:0.47852, MSE: 0.21636 , Pearson Correlation: 0.83681 with p-value: 0.00E+00 , Concordance Index: 0.84312\n",
      "Training at Epoch 65 iteration 0 with loss 0.17417. Total time 4.70777 hours\n",
      "Training at Epoch 65 iteration 100 with loss 0.18640. Total time 4.71777 hours\n",
      "Training at Epoch 65 iteration 200 with loss 0.20651. Total time 4.72805 hours\n",
      "Training at Epoch 65 iteration 300 with loss 0.13256. Total time 4.73805 hours\n",
      "Training at Epoch 65 iteration 400 with loss 0.21220. Total time 4.74805 hours\n",
      "Training at Epoch 65 iteration 500 with loss 0.23981. Total time 4.75833 hours\n",
      "Training at Epoch 65 iteration 600 with loss 0.24227. Total time 4.76833 hours\n",
      "Validation at Epoch 65 with loss:0.20169, MSE: 0.22286 , Pearson Correlation: 0.83382 with p-value: 0.00E+00 , Concordance Index: 0.84429\n",
      "Training at Epoch 66 iteration 0 with loss 0.14833. Total time 4.78111 hours\n",
      "Training at Epoch 66 iteration 100 with loss 0.15083. Total time 4.79111 hours\n",
      "Training at Epoch 66 iteration 200 with loss 0.20989. Total time 4.80138 hours\n",
      "Training at Epoch 66 iteration 300 with loss 0.19068. Total time 4.81166 hours\n",
      "Training at Epoch 66 iteration 400 with loss 0.18260. Total time 4.82166 hours\n",
      "Training at Epoch 66 iteration 500 with loss 0.23818. Total time 4.83194 hours\n",
      "Training at Epoch 66 iteration 600 with loss 0.23141. Total time 4.84194 hours\n",
      "Validation at Epoch 66 with loss:0.20448, MSE: 0.23102 , Pearson Correlation: 0.82950 with p-value: 0.00E+00 , Concordance Index: 0.84383\n",
      "Training at Epoch 67 iteration 0 with loss 0.31280. Total time 4.855 hours\n",
      "Training at Epoch 67 iteration 100 with loss 0.19445. Total time 4.865 hours\n",
      "Training at Epoch 67 iteration 200 with loss 0.24081. Total time 4.87527 hours\n",
      "Training at Epoch 67 iteration 300 with loss 0.22390. Total time 4.88527 hours\n",
      "Training at Epoch 67 iteration 400 with loss 0.18967. Total time 4.89555 hours\n",
      "Training at Epoch 67 iteration 500 with loss 0.31209. Total time 4.90555 hours\n",
      "Training at Epoch 67 iteration 600 with loss 0.15517. Total time 4.91583 hours\n",
      "Validation at Epoch 67 with loss:0.09656, MSE: 0.21513 , Pearson Correlation: 0.83548 with p-value: 0.00E+00 , Concordance Index: 0.84490\n",
      "Training at Epoch 68 iteration 0 with loss 0.17706. Total time 4.92861 hours\n",
      "Training at Epoch 68 iteration 100 with loss 0.18088. Total time 4.93888 hours\n",
      "Training at Epoch 68 iteration 200 with loss 0.19195. Total time 4.94916 hours\n",
      "Training at Epoch 68 iteration 300 with loss 0.14602. Total time 4.95916 hours\n",
      "Training at Epoch 68 iteration 400 with loss 0.18448. Total time 4.96944 hours\n",
      "Training at Epoch 68 iteration 500 with loss 0.18304. Total time 4.97972 hours\n",
      "Training at Epoch 68 iteration 600 with loss 0.29510. Total time 4.99 hours\n",
      "Validation at Epoch 68 with loss:0.13636, MSE: 0.22001 , Pearson Correlation: 0.83206 with p-value: 0.00E+00 , Concordance Index: 0.84261\n",
      "Training at Epoch 69 iteration 0 with loss 0.20703. Total time 5.00305 hours\n",
      "Training at Epoch 69 iteration 100 with loss 0.20172. Total time 5.01361 hours\n",
      "Training at Epoch 69 iteration 200 with loss 0.25985. Total time 5.02388 hours\n",
      "Training at Epoch 69 iteration 300 with loss 0.17057. Total time 5.03416 hours\n",
      "Training at Epoch 69 iteration 400 with loss 0.24098. Total time 5.04472 hours\n",
      "Training at Epoch 69 iteration 500 with loss 0.11269. Total time 5.05527 hours\n",
      "Training at Epoch 69 iteration 600 with loss 0.29383. Total time 5.06555 hours\n",
      "Validation at Epoch 69 with loss:0.18560, MSE: 0.21667 , Pearson Correlation: 0.83413 with p-value: 0.00E+00 , Concordance Index: 0.84647\n",
      "Training at Epoch 70 iteration 0 with loss 0.18984. Total time 5.07861 hours\n",
      "Training at Epoch 70 iteration 100 with loss 0.16778. Total time 5.08916 hours\n",
      "Training at Epoch 70 iteration 200 with loss 0.13494. Total time 5.09944 hours\n",
      "Training at Epoch 70 iteration 300 with loss 0.17464. Total time 5.10944 hours\n",
      "Training at Epoch 70 iteration 400 with loss 0.22924. Total time 5.11916 hours\n",
      "Training at Epoch 70 iteration 500 with loss 0.24843. Total time 5.12888 hours\n",
      "Training at Epoch 70 iteration 600 with loss 0.26110. Total time 5.13861 hours\n",
      "Validation at Epoch 70 with loss:0.12327, MSE: 0.21265 , Pearson Correlation: 0.83548 with p-value: 0.00E+00 , Concordance Index: 0.84536\n",
      "Training at Epoch 71 iteration 0 with loss 0.19557. Total time 5.15138 hours\n",
      "Training at Epoch 71 iteration 100 with loss 0.19377. Total time 5.16166 hours\n",
      "Training at Epoch 71 iteration 200 with loss 0.24411. Total time 5.17194 hours\n",
      "Training at Epoch 71 iteration 300 with loss 0.13548. Total time 5.18194 hours\n",
      "Training at Epoch 71 iteration 400 with loss 0.19557. Total time 5.19222 hours\n",
      "Training at Epoch 71 iteration 500 with loss 0.21364. Total time 5.20222 hours\n",
      "Training at Epoch 71 iteration 600 with loss 0.18525. Total time 5.2125 hours\n",
      "Validation at Epoch 71 with loss:0.28596, MSE: 0.21728 , Pearson Correlation: 0.83411 with p-value: 0.00E+00 , Concordance Index: 0.84659\n",
      "Training at Epoch 72 iteration 0 with loss 0.13897. Total time 5.22555 hours\n",
      "Training at Epoch 72 iteration 100 with loss 0.21249. Total time 5.23555 hours\n",
      "Training at Epoch 72 iteration 200 with loss 0.24889. Total time 5.24583 hours\n",
      "Training at Epoch 72 iteration 300 with loss 0.19834. Total time 5.25583 hours\n",
      "Training at Epoch 72 iteration 400 with loss 0.15747. Total time 5.26611 hours\n",
      "Training at Epoch 72 iteration 500 with loss 0.18488. Total time 5.27611 hours\n",
      "Training at Epoch 72 iteration 600 with loss 0.27776. Total time 5.28638 hours\n",
      "Validation at Epoch 72 with loss:0.14168, MSE: 0.21060 , Pearson Correlation: 0.83917 with p-value: 0.00E+00 , Concordance Index: 0.84854\n",
      "Training at Epoch 73 iteration 0 with loss 0.16405. Total time 5.29916 hours\n",
      "Training at Epoch 73 iteration 100 with loss 0.17992. Total time 5.30944 hours\n",
      "Training at Epoch 73 iteration 200 with loss 0.24046. Total time 5.31972 hours\n",
      "Training at Epoch 73 iteration 300 with loss 0.13963. Total time 5.32972 hours\n",
      "Training at Epoch 73 iteration 400 with loss 0.15236. Total time 5.34 hours\n",
      "Training at Epoch 73 iteration 500 with loss 0.11855. Total time 5.35 hours\n",
      "Training at Epoch 73 iteration 600 with loss 0.16681. Total time 5.36 hours\n",
      "Validation at Epoch 73 with loss:0.20288, MSE: 0.21755 , Pearson Correlation: 0.83627 with p-value: 0.00E+00 , Concordance Index: 0.84717\n",
      "Training at Epoch 74 iteration 0 with loss 0.15445. Total time 5.37305 hours\n",
      "Training at Epoch 74 iteration 100 with loss 0.14710. Total time 5.38305 hours\n",
      "Training at Epoch 74 iteration 200 with loss 0.18042. Total time 5.39305 hours\n",
      "Training at Epoch 74 iteration 300 with loss 0.20061. Total time 5.40305 hours\n",
      "Training at Epoch 74 iteration 400 with loss 0.33137. Total time 5.41305 hours\n",
      "Training at Epoch 74 iteration 500 with loss 0.14498. Total time 5.42277 hours\n",
      "Training at Epoch 74 iteration 600 with loss 0.21696. Total time 5.4325 hours\n",
      "Validation at Epoch 74 with loss:0.16589, MSE: 0.20471 , Pearson Correlation: 0.84223 with p-value: 0.00E+00 , Concordance Index: 0.84840\n",
      "Training at Epoch 75 iteration 0 with loss 0.18718. Total time 5.445 hours\n",
      "Training at Epoch 75 iteration 100 with loss 0.16564. Total time 5.45472 hours\n",
      "Training at Epoch 75 iteration 200 with loss 0.13655. Total time 5.46444 hours\n",
      "Training at Epoch 75 iteration 300 with loss 0.22915. Total time 5.47388 hours\n",
      "Training at Epoch 75 iteration 400 with loss 0.19767. Total time 5.48361 hours\n",
      "Training at Epoch 75 iteration 500 with loss 0.15501. Total time 5.49305 hours\n",
      "Training at Epoch 75 iteration 600 with loss 0.17490. Total time 5.50277 hours\n",
      "Validation at Epoch 75 with loss:0.21457, MSE: 0.20992 , Pearson Correlation: 0.83786 with p-value: 0.00E+00 , Concordance Index: 0.84840\n",
      "Training at Epoch 76 iteration 0 with loss 0.15276. Total time 5.51555 hours\n",
      "Training at Epoch 76 iteration 100 with loss 0.14794. Total time 5.52527 hours\n",
      "Training at Epoch 76 iteration 200 with loss 0.22191. Total time 5.535 hours\n",
      "Training at Epoch 76 iteration 300 with loss 0.12338. Total time 5.545 hours\n",
      "Training at Epoch 76 iteration 400 with loss 0.14389. Total time 5.55527 hours\n",
      "Training at Epoch 76 iteration 500 with loss 0.24351. Total time 5.56555 hours\n",
      "Training at Epoch 76 iteration 600 with loss 0.18414. Total time 5.57583 hours\n",
      "Validation at Epoch 76 with loss:0.12461, MSE: 0.20638 , Pearson Correlation: 0.84097 with p-value: 0.00E+00 , Concordance Index: 0.84832\n",
      "Training at Epoch 77 iteration 0 with loss 0.19800. Total time 5.58888 hours\n",
      "Training at Epoch 77 iteration 100 with loss 0.17826. Total time 5.59944 hours\n",
      "Training at Epoch 77 iteration 200 with loss 0.11934. Total time 5.60972 hours\n",
      "Training at Epoch 77 iteration 300 with loss 0.23474. Total time 5.62027 hours\n",
      "Training at Epoch 77 iteration 400 with loss 0.18130. Total time 5.63055 hours\n",
      "Training at Epoch 77 iteration 500 with loss 0.19873. Total time 5.64111 hours\n",
      "Training at Epoch 77 iteration 600 with loss 0.23279. Total time 5.65138 hours\n",
      "Validation at Epoch 77 with loss:0.12686, MSE: 0.20565 , Pearson Correlation: 0.84283 with p-value: 0.00E+00 , Concordance Index: 0.84780\n",
      "Training at Epoch 78 iteration 0 with loss 0.17634. Total time 5.66444 hours\n",
      "Training at Epoch 78 iteration 100 with loss 0.24895. Total time 5.675 hours\n",
      "Training at Epoch 78 iteration 200 with loss 0.18500. Total time 5.68527 hours\n",
      "Training at Epoch 78 iteration 300 with loss 0.21752. Total time 5.69583 hours\n",
      "Training at Epoch 78 iteration 400 with loss 0.14530. Total time 5.70611 hours\n",
      "Training at Epoch 78 iteration 500 with loss 0.20214. Total time 5.71638 hours\n",
      "Training at Epoch 78 iteration 600 with loss 0.29748. Total time 5.72694 hours\n",
      "Validation at Epoch 78 with loss:0.35849, MSE: 0.22879 , Pearson Correlation: 0.83226 with p-value: 0.00E+00 , Concordance Index: 0.84591\n",
      "Training at Epoch 79 iteration 0 with loss 0.13989. Total time 5.74 hours\n",
      "Training at Epoch 79 iteration 100 with loss 0.15486. Total time 5.75027 hours\n",
      "Training at Epoch 79 iteration 200 with loss 0.19892. Total time 5.76055 hours\n",
      "Training at Epoch 79 iteration 300 with loss 0.14026. Total time 5.77111 hours\n",
      "Training at Epoch 79 iteration 400 with loss 0.14652. Total time 5.78111 hours\n",
      "Training at Epoch 79 iteration 500 with loss 0.15347. Total time 5.79138 hours\n",
      "Training at Epoch 79 iteration 600 with loss 0.18612. Total time 5.80166 hours\n",
      "Validation at Epoch 79 with loss:0.16060, MSE: 0.21992 , Pearson Correlation: 0.83639 with p-value: 0.00E+00 , Concordance Index: 0.84325\n",
      "Training at Epoch 80 iteration 0 with loss 0.18136. Total time 5.81472 hours\n",
      "Training at Epoch 80 iteration 100 with loss 0.14164. Total time 5.82444 hours\n",
      "Training at Epoch 80 iteration 200 with loss 0.12345. Total time 5.83472 hours\n",
      "Training at Epoch 80 iteration 300 with loss 0.18592. Total time 5.84527 hours\n",
      "Training at Epoch 80 iteration 400 with loss 0.18346. Total time 5.85583 hours\n",
      "Training at Epoch 80 iteration 500 with loss 0.17621. Total time 5.86611 hours\n",
      "Training at Epoch 80 iteration 600 with loss 0.17212. Total time 5.87611 hours\n",
      "Validation at Epoch 80 with loss:0.15517, MSE: 0.20651 , Pearson Correlation: 0.84315 with p-value: 0.00E+00 , Concordance Index: 0.84943\n",
      "Training at Epoch 81 iteration 0 with loss 0.15285. Total time 5.88861 hours\n",
      "Training at Epoch 81 iteration 100 with loss 0.13974. Total time 5.89833 hours\n",
      "Training at Epoch 81 iteration 200 with loss 0.17733. Total time 5.90777 hours\n",
      "Training at Epoch 81 iteration 300 with loss 0.15789. Total time 5.9175 hours\n",
      "Training at Epoch 81 iteration 400 with loss 0.17069. Total time 5.92694 hours\n",
      "Training at Epoch 81 iteration 500 with loss 0.10076. Total time 5.93666 hours\n",
      "Training at Epoch 81 iteration 600 with loss 0.17582. Total time 5.94611 hours\n",
      "Validation at Epoch 81 with loss:0.20992, MSE: 0.20867 , Pearson Correlation: 0.84082 with p-value: 0.00E+00 , Concordance Index: 0.84842\n",
      "Training at Epoch 82 iteration 0 with loss 0.17180. Total time 5.95944 hours\n",
      "Training at Epoch 82 iteration 100 with loss 0.19909. Total time 5.96944 hours\n",
      "Training at Epoch 82 iteration 200 with loss 0.21137. Total time 5.97972 hours\n",
      "Training at Epoch 82 iteration 300 with loss 0.18122. Total time 5.98972 hours\n",
      "Training at Epoch 82 iteration 400 with loss 0.20815. Total time 5.99972 hours\n",
      "Training at Epoch 82 iteration 500 with loss 0.15439. Total time 6.01 hours\n",
      "Training at Epoch 82 iteration 600 with loss 0.21729. Total time 6.02055 hours\n",
      "Validation at Epoch 82 with loss:0.17416, MSE: 0.21423 , Pearson Correlation: 0.83702 with p-value: 0.00E+00 , Concordance Index: 0.85006\n",
      "Training at Epoch 83 iteration 0 with loss 0.15840. Total time 6.03388 hours\n",
      "Training at Epoch 83 iteration 100 with loss 0.15307. Total time 6.04416 hours\n",
      "Training at Epoch 83 iteration 200 with loss 0.10275. Total time 6.05444 hours\n",
      "Training at Epoch 83 iteration 300 with loss 0.12897. Total time 6.06472 hours\n",
      "Training at Epoch 83 iteration 400 with loss 0.17314. Total time 6.075 hours\n",
      "Training at Epoch 83 iteration 500 with loss 0.14518. Total time 6.08527 hours\n",
      "Training at Epoch 83 iteration 600 with loss 0.13965. Total time 6.09527 hours\n",
      "Validation at Epoch 83 with loss:0.20763, MSE: 0.20845 , Pearson Correlation: 0.83997 with p-value: 0.00E+00 , Concordance Index: 0.84927\n",
      "Training at Epoch 84 iteration 0 with loss 0.14941. Total time 6.10833 hours\n",
      "Training at Epoch 84 iteration 100 with loss 0.11944. Total time 6.11861 hours\n",
      "Training at Epoch 84 iteration 200 with loss 0.17881. Total time 6.12888 hours\n",
      "Training at Epoch 84 iteration 300 with loss 0.19526. Total time 6.13888 hours\n",
      "Training at Epoch 84 iteration 400 with loss 0.15528. Total time 6.14916 hours\n",
      "Training at Epoch 84 iteration 500 with loss 0.17835. Total time 6.15916 hours\n",
      "Training at Epoch 84 iteration 600 with loss 0.21544. Total time 6.16944 hours\n",
      "Validation at Epoch 84 with loss:0.10871, MSE: 0.20909 , Pearson Correlation: 0.84027 with p-value: 0.00E+00 , Concordance Index: 0.84653\n",
      "Training at Epoch 85 iteration 0 with loss 0.25509. Total time 6.1825 hours\n",
      "Training at Epoch 85 iteration 100 with loss 0.24008. Total time 6.19277 hours\n",
      "Training at Epoch 85 iteration 200 with loss 0.16607. Total time 6.20333 hours\n",
      "Training at Epoch 85 iteration 300 with loss 0.12517. Total time 6.21361 hours\n",
      "Training at Epoch 85 iteration 400 with loss 0.12341. Total time 6.22416 hours\n",
      "Training at Epoch 85 iteration 500 with loss 0.11566. Total time 6.23472 hours\n",
      "Training at Epoch 85 iteration 600 with loss 0.15873. Total time 6.245 hours\n",
      "Validation at Epoch 85 with loss:0.09558, MSE: 0.20789 , Pearson Correlation: 0.84375 with p-value: 0.00E+00 , Concordance Index: 0.85192\n",
      "Training at Epoch 86 iteration 0 with loss 0.17316. Total time 6.25833 hours\n",
      "Training at Epoch 86 iteration 100 with loss 0.09507. Total time 6.26861 hours\n",
      "Training at Epoch 86 iteration 200 with loss 0.25253. Total time 6.27916 hours\n",
      "Training at Epoch 86 iteration 300 with loss 0.16787. Total time 6.28944 hours\n",
      "Training at Epoch 86 iteration 400 with loss 0.17197. Total time 6.29972 hours\n",
      "Training at Epoch 86 iteration 500 with loss 0.23065. Total time 6.31 hours\n",
      "Training at Epoch 86 iteration 600 with loss 0.20216. Total time 6.32027 hours\n",
      "Validation at Epoch 86 with loss:0.09617, MSE: 0.20589 , Pearson Correlation: 0.84131 with p-value: 0.00E+00 , Concordance Index: 0.85001\n",
      "Training at Epoch 87 iteration 0 with loss 0.18978. Total time 6.33361 hours\n",
      "Training at Epoch 87 iteration 100 with loss 0.23028. Total time 6.34388 hours\n",
      "Training at Epoch 87 iteration 200 with loss 0.19661. Total time 6.35444 hours\n",
      "Training at Epoch 87 iteration 300 with loss 0.11815. Total time 6.365 hours\n",
      "Training at Epoch 87 iteration 400 with loss 0.14978. Total time 6.37527 hours\n",
      "Training at Epoch 87 iteration 500 with loss 0.20925. Total time 6.38583 hours\n",
      "Training at Epoch 87 iteration 600 with loss 0.15903. Total time 6.39611 hours\n",
      "Validation at Epoch 87 with loss:0.34849, MSE: 0.20623 , Pearson Correlation: 0.84096 with p-value: 0.00E+00 , Concordance Index: 0.84911\n",
      "Training at Epoch 88 iteration 0 with loss 0.18076. Total time 6.40944 hours\n",
      "Training at Epoch 88 iteration 100 with loss 0.13050. Total time 6.41972 hours\n",
      "Training at Epoch 88 iteration 200 with loss 0.14370. Total time 6.43 hours\n",
      "Training at Epoch 88 iteration 300 with loss 0.14533. Total time 6.44027 hours\n",
      "Training at Epoch 88 iteration 400 with loss 0.18240. Total time 6.45027 hours\n",
      "Training at Epoch 88 iteration 500 with loss 0.16595. Total time 6.46055 hours\n",
      "Training at Epoch 88 iteration 600 with loss 0.14056. Total time 6.47083 hours\n",
      "Validation at Epoch 88 with loss:0.10191, MSE: 0.20240 , Pearson Correlation: 0.84817 with p-value: 0.00E+00 , Concordance Index: 0.85162\n",
      "Training at Epoch 89 iteration 0 with loss 0.16564. Total time 6.48361 hours\n",
      "Training at Epoch 89 iteration 100 with loss 0.20062. Total time 6.49388 hours\n",
      "Training at Epoch 89 iteration 200 with loss 0.19096. Total time 6.50416 hours\n",
      "Training at Epoch 89 iteration 300 with loss 0.12740. Total time 6.51416 hours\n",
      "Training at Epoch 89 iteration 400 with loss 0.19492. Total time 6.52444 hours\n",
      "Training at Epoch 89 iteration 500 with loss 0.16890. Total time 6.53472 hours\n",
      "Training at Epoch 89 iteration 600 with loss 0.15822. Total time 6.54472 hours\n",
      "Validation at Epoch 89 with loss:0.12816, MSE: 0.21498 , Pearson Correlation: 0.84057 with p-value: 0.00E+00 , Concordance Index: 0.84981\n",
      "Training at Epoch 90 iteration 0 with loss 0.13498. Total time 6.55777 hours\n",
      "Training at Epoch 90 iteration 100 with loss 0.16402. Total time 6.56805 hours\n",
      "Training at Epoch 90 iteration 200 with loss 0.11678. Total time 6.57833 hours\n",
      "Training at Epoch 90 iteration 300 with loss 0.17006. Total time 6.58833 hours\n",
      "Training at Epoch 90 iteration 400 with loss 0.12158. Total time 6.59861 hours\n",
      "Training at Epoch 90 iteration 500 with loss 0.22181. Total time 6.60888 hours\n",
      "Training at Epoch 90 iteration 600 with loss 0.19007. Total time 6.61916 hours\n",
      "Validation at Epoch 90 with loss:0.15202, MSE: 0.20161 , Pearson Correlation: 0.84690 with p-value: 0.00E+00 , Concordance Index: 0.85227\n",
      "Training at Epoch 91 iteration 0 with loss 0.21185. Total time 6.63222 hours\n",
      "Training at Epoch 91 iteration 100 with loss 0.15612. Total time 6.6425 hours\n",
      "Training at Epoch 91 iteration 200 with loss 0.17576. Total time 6.6525 hours\n",
      "Training at Epoch 91 iteration 300 with loss 0.19028. Total time 6.66305 hours\n",
      "Training at Epoch 91 iteration 400 with loss 0.15643. Total time 6.67305 hours\n",
      "Training at Epoch 91 iteration 500 with loss 0.19027. Total time 6.68333 hours\n",
      "Training at Epoch 91 iteration 600 with loss 0.12361. Total time 6.69361 hours\n",
      "Validation at Epoch 91 with loss:0.37483, MSE: 0.20848 , Pearson Correlation: 0.84329 with p-value: 0.00E+00 , Concordance Index: 0.85328\n",
      "Training at Epoch 92 iteration 0 with loss 0.14189. Total time 6.70666 hours\n",
      "Training at Epoch 92 iteration 100 with loss 0.17439. Total time 6.71694 hours\n",
      "Training at Epoch 92 iteration 200 with loss 0.15459. Total time 6.72694 hours\n",
      "Training at Epoch 92 iteration 300 with loss 0.12281. Total time 6.73722 hours\n",
      "Training at Epoch 92 iteration 400 with loss 0.13814. Total time 6.7475 hours\n",
      "Training at Epoch 92 iteration 500 with loss 0.15272. Total time 6.7575 hours\n",
      "Training at Epoch 92 iteration 600 with loss 0.18408. Total time 6.76777 hours\n",
      "Validation at Epoch 92 with loss:0.11115, MSE: 0.20801 , Pearson Correlation: 0.84354 with p-value: 0.00E+00 , Concordance Index: 0.85030\n",
      "Training at Epoch 93 iteration 0 with loss 0.16867. Total time 6.78083 hours\n",
      "Training at Epoch 93 iteration 100 with loss 0.16806. Total time 6.79111 hours\n",
      "Training at Epoch 93 iteration 200 with loss 0.20023. Total time 6.80138 hours\n",
      "Training at Epoch 93 iteration 300 with loss 0.16777. Total time 6.81194 hours\n",
      "Training at Epoch 93 iteration 400 with loss 0.14769. Total time 6.8225 hours\n",
      "Training at Epoch 93 iteration 500 with loss 0.19697. Total time 6.83277 hours\n",
      "Training at Epoch 93 iteration 600 with loss 0.15137. Total time 6.84333 hours\n",
      "Validation at Epoch 93 with loss:0.15604, MSE: 0.21579 , Pearson Correlation: 0.84166 with p-value: 0.00E+00 , Concordance Index: 0.84973\n",
      "Training at Epoch 94 iteration 0 with loss 0.13956. Total time 6.85638 hours\n",
      "Training at Epoch 94 iteration 100 with loss 0.21191. Total time 6.86694 hours\n",
      "Training at Epoch 94 iteration 200 with loss 0.14134. Total time 6.87722 hours\n",
      "Training at Epoch 94 iteration 300 with loss 0.09997. Total time 6.88777 hours\n",
      "Training at Epoch 94 iteration 400 with loss 0.20375. Total time 6.89805 hours\n",
      "Training at Epoch 94 iteration 500 with loss 0.10334. Total time 6.90833 hours\n",
      "Training at Epoch 94 iteration 600 with loss 0.14347. Total time 6.91805 hours\n",
      "Validation at Epoch 94 with loss:0.25189, MSE: 0.22209 , Pearson Correlation: 0.83109 with p-value: 0.00E+00 , Concordance Index: 0.84161\n",
      "Training at Epoch 95 iteration 0 with loss 0.15402. Total time 6.93111 hours\n",
      "Training at Epoch 95 iteration 100 with loss 0.14216. Total time 6.94138 hours\n",
      "Training at Epoch 95 iteration 200 with loss 0.18060. Total time 6.95194 hours\n",
      "Training at Epoch 95 iteration 300 with loss 0.14281. Total time 6.96222 hours\n",
      "Training at Epoch 95 iteration 400 with loss 0.29945. Total time 6.9725 hours\n",
      "Training at Epoch 95 iteration 500 with loss 0.16097. Total time 6.98277 hours\n",
      "Training at Epoch 95 iteration 600 with loss 0.14611. Total time 6.99333 hours\n",
      "Validation at Epoch 95 with loss:0.08736, MSE: 0.20895 , Pearson Correlation: 0.84300 with p-value: 0.00E+00 , Concordance Index: 0.85169\n",
      "Training at Epoch 96 iteration 0 with loss 0.14823. Total time 7.00666 hours\n",
      "Training at Epoch 96 iteration 100 with loss 0.14914. Total time 7.01722 hours\n",
      "Training at Epoch 96 iteration 200 with loss 0.20486. Total time 7.02722 hours\n",
      "Training at Epoch 96 iteration 300 with loss 0.11972. Total time 7.03722 hours\n",
      "Training at Epoch 96 iteration 400 with loss 0.19062. Total time 7.04722 hours\n",
      "Training at Epoch 96 iteration 500 with loss 0.12355. Total time 7.0575 hours\n",
      "Training at Epoch 96 iteration 600 with loss 0.18635. Total time 7.06777 hours\n",
      "Validation at Epoch 96 with loss:0.18514, MSE: 0.20157 , Pearson Correlation: 0.84695 with p-value: 0.00E+00 , Concordance Index: 0.85146\n",
      "Training at Epoch 97 iteration 0 with loss 0.14208. Total time 7.08083 hours\n",
      "Training at Epoch 97 iteration 100 with loss 0.16724. Total time 7.09111 hours\n",
      "Training at Epoch 97 iteration 200 with loss 0.15814. Total time 7.10138 hours\n",
      "Training at Epoch 97 iteration 300 with loss 0.14509. Total time 7.11138 hours\n",
      "Training at Epoch 97 iteration 400 with loss 0.16160. Total time 7.12194 hours\n",
      "Training at Epoch 97 iteration 500 with loss 0.19670. Total time 7.13222 hours\n",
      "Training at Epoch 97 iteration 600 with loss 0.13581. Total time 7.1425 hours\n",
      "Validation at Epoch 97 with loss:0.18164, MSE: 0.20619 , Pearson Correlation: 0.84165 with p-value: 0.00E+00 , Concordance Index: 0.85047\n",
      "Training at Epoch 98 iteration 0 with loss 0.14658. Total time 7.15555 hours\n",
      "Training at Epoch 98 iteration 100 with loss 0.26570. Total time 7.16583 hours\n",
      "Training at Epoch 98 iteration 200 with loss 0.18158. Total time 7.17583 hours\n",
      "Training at Epoch 98 iteration 300 with loss 0.11225. Total time 7.18611 hours\n",
      "Training at Epoch 98 iteration 400 with loss 0.16463. Total time 7.19666 hours\n",
      "Training at Epoch 98 iteration 500 with loss 0.14399. Total time 7.20694 hours\n",
      "Training at Epoch 98 iteration 600 with loss 0.14954. Total time 7.21722 hours\n",
      "Validation at Epoch 98 with loss:0.22094, MSE: 0.20642 , Pearson Correlation: 0.84390 with p-value: 0.00E+00 , Concordance Index: 0.85224\n",
      "Training at Epoch 99 iteration 0 with loss 0.20779. Total time 7.23055 hours\n",
      "Training at Epoch 99 iteration 100 with loss 0.12804. Total time 7.24111 hours\n",
      "Training at Epoch 99 iteration 200 with loss 0.12432. Total time 7.25138 hours\n",
      "Training at Epoch 99 iteration 300 with loss 0.16800. Total time 7.26166 hours\n",
      "Training at Epoch 99 iteration 400 with loss 0.12526. Total time 7.27194 hours\n",
      "Training at Epoch 99 iteration 500 with loss 0.09726. Total time 7.28194 hours\n",
      "Training at Epoch 99 iteration 600 with loss 0.14391. Total time 7.29222 hours\n",
      "Validation at Epoch 99 with loss:0.35077, MSE: 0.20623 , Pearson Correlation: 0.84163 with p-value: 0.00E+00 , Concordance Index: 0.85047\n",
      "Training at Epoch 100 iteration 0 with loss 0.14451. Total time 7.30527 hours\n",
      "Training at Epoch 100 iteration 100 with loss 0.14444. Total time 7.31527 hours\n",
      "Training at Epoch 100 iteration 200 with loss 0.12114. Total time 7.32555 hours\n",
      "Training at Epoch 100 iteration 300 with loss 0.11574. Total time 7.33555 hours\n",
      "Training at Epoch 100 iteration 400 with loss 0.11712. Total time 7.34583 hours\n",
      "Training at Epoch 100 iteration 500 with loss 0.18555. Total time 7.35611 hours\n",
      "Training at Epoch 100 iteration 600 with loss 0.21827. Total time 7.36611 hours\n",
      "Validation at Epoch 100 with loss:0.14806, MSE: 0.20810 , Pearson Correlation: 0.84095 with p-value: 0.00E+00 , Concordance Index: 0.84938\n",
      "--- Go for Testing ---\n",
      "Testing MSE: 0.20486105068748725 , Pearson Correlation: 0.8457318342856956 with p-value: 0.00E+00 , Concordance Index: 0.8506156395143659\n",
      "--- Training Finished ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model training\n",
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model saving\n",
    "model.save_model('./pretrained_model/CNN_CNN_KIBA_after/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
